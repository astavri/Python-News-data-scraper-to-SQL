# Shoutout to kotartemiy for pygooglenews
# this whole project is based majority based on him and his partners' work, otherwise id have a LOT more work to reach my goal in the sake of learning purposes
# I had this idea to learn python and SQL better. Scrape news headlines, export to SQL, sift/count/analyze data in SQL or Excel based on header keywords.
# make another table set based on other set of data that has daily/weekly data, such as gun purchases, stocks, violence, crime
# correlate it with this factor, possibly export results to Excel for further analysis.
# i do more explaination than necessary using the mostly so I can learn and remember the methods used, so apologies if its too much, hopefully it is beneficial


import mysql.connector
from datetime import datetime, timedelta
from pygooglenews import GoogleNews

mydb = mysql.connector.connect(
    host="localhost",
    user="root",
    password="XXXXXXX",
    database="stocks") #Database Name in SQL

gn = GoogleNews()
cursor = mydb.cursor()

add_article =   ("INSERT IGNORE INTO articletitles"        #Table Name in SQL: easier to create table in mySQL, "IGNORE" ignores errors from SQL which can stall due to title char limits or other things.     
                "(title, published, search_keyword)"    #Must match table parameters in SQL
                "VALUES (%s, %s, %s)")                  #Must match int or str in SQL

start_date = datetime(2021, 1, 23)                      #The range here is important because Google only limits 100 results per search.
min_date = start_date                                   #looping it instead of using from_ and to_ feature is a workaround for this.
max_date = datetime(2021, 2, 23)

#You can enter any of keywords you want or remove in the list
searchlist = ["stocks", "bonds"]
i = 0;
sizeofList = len(searchlist)

while i < sizeofList:                                   #WHile loop sets a condition to sort through list of search keywords
    while  min_date != max_date:                        #While loop conditions set to run dates min-max, adding a day for each search query
        min1_date = min_date + timedelta(days=1)        #this step is added because using only (from_ 1/1/2000, to_ 1/1/2000) shows no results
        print("From:"+min_date.strftime('%Y-%m-%d'));   #ie. it appears you cannot search results from pygooglenews from one specific day in time.
        print("To:"+min1_date.strftime('%Y-%m-%d'));
        search = gn.search(searchlist[i], from_=min_date.strftime('%Y-%m-%d'), to_=min1_date.strftime('%Y-%m-%d'))

        for item in search['entries']:
            print(item['title']);
            #print(item["published"]);
            data_article = (item['title'], item["published"], searchlist[i]);       #mysql.connector
            cursor.execute(add_article, data_article);                              #mysql. connecor executes by using cursor
            #print(item['link']) #should we add links to the SQL?

            mydb.commit()

        min_date = min_date + timedelta(days=1)
    else: min_date = start_date                         #this is to reset date for this keyword otherwise searchword loop ends due to min_date=max from the first search keyword
                                                        
    i += 1                                              #adds count to search the next keyword
